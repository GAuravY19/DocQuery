# ğŸ“„ DocQuery â€” RAG-Based PDF QnA System

DocQuery is a **Retrieval-Augmented Generation (RAG)** based web application that allows users to upload PDF documents and ask natural-language questions to get **accurate, document-grounded answers**.

The system is designed for **students and learners** who want to interactively explore textbooks, notes, research papers, and other long PDFs using Generative AI.

---

## ğŸš€ Features

* ğŸ“¤ Upload any PDF document (lecture notes, textbooks, research papers)
* ğŸ” Ask questions and get answers **strictly based on the uploaded PDF**
* ğŸ§  Uses **RAG (Retrieval-Augmented Generation)** for high accuracy
* ğŸ“š Handles **large PDFs (1000+ pages)** efficiently
* ğŸ’¬ Chat-style interface similar to ChatGPT
* ğŸ§© Semantic chunking + vector search
* ğŸ—‚ Vector stores saved locally and reused across requests
* ğŸ” Session-based isolation (each user gets their own document context)

---

## ğŸ§  How DocQuery Works (High-Level)

```
PDF Upload
   â†“
PDF Text Extraction
   â†“
Semantic Chunking
   â†“
Embeddings Generation
   â†“
Vector Store (FAISS)
   â†“
User Query
   â†“
Relevant Chunk Retrieval
   â†“
LLM Generates Answer
```

This approach ensures:

* Minimal hallucination
* Accurate, context-aware responses
* Scalable handling of large documents

---

## ğŸ›  Tech Stack

### Backend

* **Flask** â€” Web framework
* **LangChain** â€” RAG pipeline orchestration
* **FAISS** â€” Vector database
* **Google Gemini / Open-Source Embeddings** â€” Text embeddings
* **Python** â€” Core language

### Frontend

* **HTML5**
* **CSS (Bootstrap)**
* **JavaScript (Fetch API)**

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/DocQuery.git
cd DocQuery
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Environment Variables

Create a `.env` file:

```env
GOOGLE_API_KEY=your_api_key_here
SECRET_KEY=your_flask_secret_key
```

---

### 5ï¸âƒ£ Run the Application

```bash
python run.py
```

Open browser at:

```
http://127.0.0.1:5000
```

---

## ğŸ’¬ Chat Workflow

1. User uploads a PDF
2. Backend extracts text and builds vector store
3. Vector store is saved locally
4. User asks questions via chat UI
5. Each question:

   * Retrieves relevant chunks
   * Passes them to the LLM
   * Returns an answer as JSON
6. Frontend updates chat UI dynamically

---

## ğŸ§© RAG Design Choices

### Chunking Strategy

* Chunk size: ~800 tokens
* Overlap: ~120 tokens

### Vector Storage

* FAISS stored locally on disk
* Vector store path saved in session
* Reloaded on each query (no re-embedding)

---

## ğŸ” Session Handling

* PDF path and vector store path stored in Flask session
* Each user session is isolated
* On session reset, vector store and uploaded PDF are deleted

---

## ğŸš« Known Limitations (Current)

* Single PDF per session
* Local vector storage (not cloud-based yet)
* No streaming responses (planned)

---

## ğŸ”® Future Enhancements

* ğŸ”— External vector databases (Pinecone / Qdrant)
* ğŸ“‘ Source citations with page numbers
* ğŸ”„ Multi-PDF support
* âš¡ Streaming responses
* â˜ï¸ Cloud deployment
* ğŸ‘¤ Authentication & user profiles

---

## ğŸ¯ Who Is This Project For?

* Students preparing for exams
* Learners reading large PDFs
* Developers learning RAG systems
* Recruiters evaluating real-world GenAI projects

---

## ğŸ§  Key Learning Outcomes

* RAG system design
* Vector database lifecycle management
* Chunking strategies for long documents
* Frontendâ€“backend chat architecture
* Production-ready Flask patterns


